{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5a80bb-c08b-4663-99d3-27d365ee74fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"api.env\")  # ðŸ‘ˆ specify file name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d482045f-e05a-45a6-8d12-80af5c046f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ""
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"api.env\")  # or just load_dotenv() if renamed\n",
    "\n",
    "print(os.getenv(\"GOOGLE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "847e68d5-2cca-452c-af81-f009bee7931e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key loaded!\n",
      "\n",
      "ðŸ¤– Chatbot Reply:\n",
      "LangGraph is a Python library built on top of LangChain that provides a way to create **stateful, multi-actor applications**. Think of it as a framework for building complex conversational AI agents and workflows that can interact with each other and maintain a shared memory.\n",
      "\n",
      "Here's a breakdown of what LangGraph is and its key features:\n",
      "\n",
      "**Core Concepts:**\n",
      "\n",
      "*   **Nodes:**  These are the building blocks of your graph. They represent individual actors or steps in your workflow.  A node can be:\n",
      "    *   **Functions:**  A Python function that takes the current state as input and returns an updated state.\n",
      "    *   **LangChain Chains/Agents:**  You can easily integrate existing LangChain chains and agents as nodes in your graph.\n",
      "    *   **Conditional Edges:**  These define the flow based on conditions.\n",
      "*   **Edges:**  These connect the nodes, defining the flow of execution.\n",
      "    *   **Normal Edges:**  A simple connection that passes the state from one node to the next.\n",
      "    *   **Conditional Edges:**  Determine which node to go to next based on the current state.  This allows for branching and decision-making within the graph.\n",
      "*   **State:**  A central concept.  The state is a Python dictionary (or any other data structure you define) that holds the information shared between the nodes. As each node executes, it can update the state.\n",
      "*   **Graph:**  The overall structure connecting nodes and edges.  You define how the nodes are connected and how the state flows through them.\n",
      "\n",
      "**Key Benefits and Features:**\n",
      "\n",
      "*   **State Management:** LangGraph's state management system makes it easy to track and update information throughout the conversation or workflow. This is crucial for building agents that can remember past interactions and make informed decisions.\n",
      "*   **Multi-Actor Collaboration:**  LangGraph simplifies the creation of systems where multiple agents can work together.  Each agent can be represented as a node, and the state allows them to share information and coordinate their actions.\n",
      "*   **Conditional Logic:**  Conditional edges enable complex decision-making within the graph.  You can define rules that determine which node to execute next based on the current state. This allows for dynamic and adaptive workflows.\n",
      "*   **Integration with LangChain:**  LangGraph is designed to work seamlessly with LangChain.  You can easily incorporate existing LangChain chains and agents into your graphs.  This allows you to leverage the power of LangChain's tools and models within a more structured and stateful framework.\n",
      "*   **Flexibility:**  You have control over the graph's structure and the logic of each node. This allows you to create highly customized and tailored solutions.\n",
      "*   **Modularity:**  The node-based architecture promotes modularity. You can easily add, remove, or modify nodes without affecting the rest of the graph.\n",
      "*   **Debugging and Visualization:**  LangGraph provides tools for visualizing the graph and debugging its execution.  This helps you understand the flow of information and identify potential issues.\n",
      "*   **Agent Orchestration:**  A primary use case is for orchestrating agents.  You can define how agents interact, when they're called, and how their outputs are combined.\n",
      "\n",
      "**Use Cases:**\n",
      "\n",
      "*   **Complex Conversational Agents:** Build agents that can handle multi-turn conversations, remember past interactions, and perform complex tasks.\n",
      "*   **Workflow Automation:** Automate complex business processes by creating graphs that define the steps and decision points.\n",
      "*   **Agent Swarms:** Create systems where multiple agents collaborate to solve a problem.\n",
      "*   **Personalized Recommendations:** Build recommendation systems that adapt to the user's preferences and history.\n",
      "*   **Game AI:**  Develop AI agents for games that can make strategic decisions and interact with the game world.\n",
      "*   **Autonomous Research Agents:**  Create agents that can perform research tasks, gather information, and generate reports.\n",
      "\n",
      "**How it differs from LangChain:**\n",
      "\n",
      "*   **LangChain:**  Primarily focused on building individual chains and agents.  It provides tools for connecting LLMs with other components (data sources, tools, etc.) and for creating sequences of operations.\n",
      "*   **LangGraph:**  Focuses on orchestrating *multiple* chains and agents in a *stateful* way.  It adds the ability to manage state, define conditional flows, and create complex interactions between different components.  You can think of LangGraph as a higher-level abstraction that builds on top of LangChain.\n",
      "\n",
      "**Example (Conceptual):**\n",
      "\n",
      "Imagine building a customer service chatbot using LangGraph.  The graph might have nodes for:\n",
      "\n",
      "1.  **Greeting:**  Welcomes the user.\n",
      "2.  **Intent Recognition:**  Uses an LLM to identify the user's intent (e.g., \"track my order,\" \"report a problem\").\n",
      "3.  **Order Tracking:**  If the intent is \"track my order,\" this node retrieves the order information.\n",
      "4.  **Problem Reporting:** If the intent is \"report a problem,\" this node gathers details about the problem.\n",
      "5.  **Escalation:**  If the problem is too complex, this node escalates the issue to a human agent.\n",
      "6.  **Feedback:**  Asks the user for feedback on the interaction.\n",
      "\n",
      "Conditional edges would determine which node to execute next based on the user's intent.  The state would store information about the user's order, the problem they're reporting, and the conversation history.\n",
      "\n",
      "**Learning Resources:**\n",
      "\n",
      "*   **LangChain Documentation:**  The official LangChain documentation has a section dedicated to LangGraph.  This is the best place to start learning about the library.\n",
      "*   **LangChain Examples:**  LangChain provides example notebooks that demonstrate how to use LangGraph to build different types of applications.\n",
      "*   **Blog Posts and Tutorials:**  There are many blog posts and tutorials online that cover LangGraph.  Search for \"LangGraph tutorial\" or \"LangGraph example\" to find these resources.\n",
      "\n",
      "In summary, LangGraph is a powerful tool for building complex, stateful AI applications. If you're working on projects that require multi-agent collaboration, conditional logic, or long-running conversations, LangGraph is definitely worth exploring.\n"
     ]
    }
   ],
   "source": [
    "from typing import List, TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load API key\n",
    "load_dotenv(\"api.env\")\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"âŒ GOOGLE_API_KEY not found in api.env\")\n",
    "\n",
    "print(\"âœ… API key loaded!\")\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: List[str]\n",
    "\n",
    "def merge_messages(old: ChatState, new: ChatState) -> ChatState:\n",
    "    return {\"messages\": old[\"messages\"] + new[\"messages\"]}\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=api_key\n",
    ")\n",
    "\n",
    "def chatbot_node(state: ChatState) -> ChatState:\n",
    "    user_input = state[\"messages\"][-1]\n",
    "    response = model.invoke(user_input)\n",
    "\n",
    "    if isinstance(response, str):\n",
    "        reply_text = response\n",
    "    elif hasattr(response, \"content\"):\n",
    "        # Try to extract text safely\n",
    "        reply_text = (\n",
    "            response.content[0].text\n",
    "            if isinstance(response.content, list) and len(response.content) > 0\n",
    "            else str(response.content)\n",
    "        )\n",
    "    else:\n",
    "        reply_text = str(response)\n",
    "\n",
    "    return {\"messages\": state[\"messages\"] + [reply_text]}\n",
    "\n",
    "graph_builder = StateGraph(ChatState, input_schema=ChatState, output_schema=ChatState, reducer=merge_messages)\n",
    "graph_builder.add_node(\"chatbot\", chatbot_node)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "input_state = {\"messages\": [\"What do you know about LangGraph?\"]}\n",
    "final_state = graph.invoke(input_state)\n",
    "\n",
    "print(\"\\nðŸ¤– Chatbot Reply:\")\n",
    "print(final_state[\"messages\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b0831-3895-45b3-b3f9-532767274d52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
